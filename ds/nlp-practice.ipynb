{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6057536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading files\n",
    "import os\n",
    "\n",
    "# for punc list\n",
    "import string\n",
    "\n",
    "# for regex \n",
    "import regex as re\n",
    "\n",
    "# for nltk (library) work\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffd776",
   "metadata": {},
   "source": [
    "Contrived NLP example:\n",
    "\n",
    "* ~read in raw text files from a directory with other stuff in it~ \n",
    "    * ~jane austen's books~\n",
    "* tokenize\n",
    "    * ~words (manually)~\n",
    "    * ~words (nltk)~\n",
    "    * ~sentences (nltk)~\n",
    "* clean\n",
    "    * ~remove punctuation (manually)~\n",
    "    * ~remove numbers (nltk)~\n",
    "    * ~remove stopwords (from pre-baked list) (manually)~\n",
    "    * ~use regex for something (manually)~\n",
    "* calculating important metrics\n",
    "    * unigrams\n",
    "    * bigrams\n",
    "    * lexicon-based\n",
    "    * most frequent words\n",
    "    * tf-idf\n",
    "    * most mentioned entities\n",
    "    * simple sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd9ee13",
   "metadata": {},
   "source": [
    "Practical Numpy example:\n",
    "\n",
    "* make a random array of 1,000 integers between 1 and 10,000\n",
    "* make an array with 17 0's\n",
    "* calculate five number summary\n",
    "* find the standard deviation and the mean\n",
    "* find the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efc64737",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in text files\n",
    "def read_austen_data(directory_name):\n",
    "    texts = []\n",
    "    files = [f for f in listdir(directory_name) if isfile(join(directory_name, f))]\n",
    "    \n",
    "    for file in files:\n",
    "        if (\"austen\" in file):\n",
    "            with open(directory_name + file, encoding=\"utf-8\") as f:\n",
    "                #lowercase text and append\n",
    "                texts.append(f.read().lower())\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4928009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "austen_books = read_austen_data(\"data/\")\n",
    "\n",
    "print(len(austen_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f266d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_tokenize(text):\n",
    "    \n",
    "    # replace new lines\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # remove punctuation here.\n",
    "    punc_list = [p for p in string.punctuation]\n",
    "    \n",
    "    text = ''.join([char for char in text if char not in punc_list])\n",
    "            \n",
    "    # we need to strip all the extraneous spaces (more than 2)\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    \n",
    "    # remove volume numbers\n",
    "    text = re.sub(\"volume i{1,}|volume [0-9]{1,}|volume one|volume two|volume three\", \"\", text)\n",
    "    \n",
    "    # listify, splitting on spaces\n",
    "    text = text.split(' ')\n",
    "\n",
    "    # the text starts as soon as we find \"chapter 1\" or \"chapter i\"\n",
    "    # so let's move the book to just its relevant parts by finding and deleting content before the first chapter 1|i\n",
    "    # since the volume-paradigm has multiple ch1, ch2, and so on\n",
    "    # first, find chapter 1, and replace everything prior\n",
    "    \n",
    "    # then, convert back to string, replace all the chapters, then convert back to list\n",
    "    for i in range(len(text) - 1):\n",
    "        window_val = ' '.join(text[i:i+2])\n",
    "        if (window_val == \"chapter 1\" or window_val == \"chapter i\"):\n",
    "            text = text[i+2:]\n",
    "            break\n",
    "    \n",
    "    # back to string\n",
    "    text = ' '.join(text)\n",
    "        \n",
    "    # replace chapters\n",
    "    text = re.sub(\"chapter [a-z]+|chapter [0-9]+\", \"\", text)\n",
    "    \n",
    "    # back to list\n",
    "    text = text.split(\" \")\n",
    "    \n",
    "    ## method extensions (pseudocode ok)\n",
    "    ## removing stop words \n",
    "        # (word for word in book if word not in stopwords)\n",
    "    ## removing numbers \n",
    "        # (word for word in book if word not in [num_list])\n",
    "        # or you could use regex across the whole thing as a string then join it back\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a0a3bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteratively call the cleaning function\n",
    "austen_books_tokenized = [manual_tokenize(book) for book in austen_books]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0f809e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['no', 'one', 'who', 'had', 'ever', 'seen', 'catherine', 'morland', 'in', 'her'], ['sir', 'walter', 'elliot', 'of', 'kellynchhall', 'in', 'somersetshire', 'was', 'a', 'man'], ['about', 'thirty', 'years', 'ago', 'miss', 'maria', 'ward', 'of', 'huntingdon', 'with'], ['emma', 'woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home'], ['it', 'is', 'a', 'truth', 'universally', 'acknowledged', 'that', 'a', 'single', 'man'], ['the', 'family', 'of', 'dashwood', 'had', 'been', 'long', 'settled', 'in', 'sussex'], ['emma', 'woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home']]\n"
     ]
    }
   ],
   "source": [
    "# first ten words of austen's books\n",
    "print([book[:10] for book in austen_books_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "df8aef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## w/ ntlk...\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def tokenize_with_nltk(book, unit):\n",
    "        \n",
    "    if (unit == 'word'):\n",
    "        tokens=nltk.word_tokenize(book)\n",
    "    \n",
    "    ## dealing with new line chars can be a little annoying\n",
    "    elif (unit == 'sentence'): \n",
    "        tokens = []\n",
    "        paragraphs = [p for p in book.split('\\n') if p]\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            if (paragraph != ''):\n",
    "                tokens.append(sent_detector.tokenize(paragraph.strip()))\n",
    "        \n",
    "        tokens = sum(tokens, [])\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "835f5586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['northanger abbey', 'biographical notice of the author', '1', 'the following pages are the production of a pen which has already contributed in no small degree to the entertainment of the public.', \"and when the public, which has not been insensible to the merits of 'sense and sensibility,' 'pride and prejudice,' 'mansfield park,' and 'emma,' shall be informed that the hand which guided that pen is now mouldering in the grave, perhaps a brief account of jane austen will be read with a kindlier sentiment than simple curiosity.\", 'short and easy will be the task of the mere biographer.', 'a life of usefulness, literature, and religion, was not by any means a life of event.', 'to those who lament their irreparable loss, it is consolatory to think that, as she never deserved disapprobation, so, in the circle of her family and friends, she never met reproof; that her wishes were not only reasonable, but gratified; and that to the little disappointments incidental to human life was never added, even for a moment, an abatement of good-will from any who knew her.', 'jane austen was born on the 16th of december, 1775, at steventon, in the county of hants.', 'her father was rector of that parish upwards of forty years.']\n"
     ]
    }
   ],
   "source": [
    "mansfield_park_nltk_sent_tokenized = tokenize_with_nltk(austen_books[0], 'sentence')\n",
    "\n",
    "## first ten \"sentences\" of Mansfield park\n",
    "## note that we have a harder time really \"cleaning\" up this text\n",
    "## for large enough corpora of course, this does not matter.\n",
    "print(mansfield_park_nltk_sent_tokenized[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2cd9ceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'present', 'age', 'it', 'is', 'hazardous', 'to', 'mention', 'accomplishments', '.', 'our', 'authoress', 'would', ',', 'probably', ',', 'have', 'been', 'inferior', 'to', 'few', 'in', 'such', 'acquirements', ',', 'had', 'she', 'not', 'been', 'so', 'superior', 'to', 'most', 'in', 'higher', 'things', '.', 'she', 'had', 'not', 'only', 'an', 'excellent', 'taste', 'for', 'drawing', ',', 'but', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "mansfield_park_nltk_word_tokenized = tokenize_with_nltk(austen_books[0], 'word')\n",
    "\n",
    "print(mansfield_park_nltk_word_tokenized[1000:1050])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c89097",
   "metadata": {},
   "source": [
    "remove punctuation - if you really wanted to, you have to do it again manually\n",
    "\n",
    "alternatively nltk has an api that lets you use your own Regexes as the delimiters but this can elad to other issues\n",
    "\n",
    "also you need to be careful about the end result here because you might not intend for Don't to split apart into 2 words.\n",
    "    \n",
    "remove numbers - similar to above, but less side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cae3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
